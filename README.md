# Final-Year-Project

User-generated hate speech and toxic content within social media is a proliferating issue, which has augmented researchers efforts into hateful content identification. Alongside an efficient automatic hate speech detection model, a sufficient amount of annotated data is also required when training a model. The lack of substantial labelled hate speech data, alongside the issue of existing biases, has been the main issue surrounding this research domain. In this work the BERT fine-tuning approach is adopted and formed in conjunction with a GUI. Thus, enabling the user to manually fetch tweets or manually input a tweet to receive an output for the binary classification hate speech/offence or neither. A robust model was produced with performance of over 86% evaluated using traditional machine learning metrics Precision, Recall, F1-score. Therefore indicating a robust model, alongside a novel application of a GUI.

#### Note: the hate_speech_train.csv is too large to upload on GitHub.
